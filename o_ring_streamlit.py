import streamlit as st
import torch
import cv2
import numpy as np
from torchvision import transforms
import torchvision.transforms.functional as F
from torchvision.utils import draw_bounding_boxes
from PIL import Image
import torchvision.models as models
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

# âœ… ëª¨ë¸ ê²½ë¡œ ì„¤ì •
MODEL_PATHS = {
    "Baseline Model": "train_test_100.pth",
    "K-Fold Model (Epoch 35)": "k_fold_35_epoch_2.pth",
    "Ensemble Model (Epoch 35)": "ensemble_model_35_epoch.pth"
}

# âœ… í´ë˜ìŠ¤ ë§¤í•‘
CLASS_NAMES = {1: "extruded", 2: "crack", 3: "cutting", 4: "side_stamped"}

# âœ… ë¼ë²¨ë³„ ìƒ‰ìƒ ì§€ì •
LABEL_COLORS = {
    "extruded": (255, 0, 0),
    "crack": (0, 0, 255),
    "cutting": (0, 255, 0),
    "side_stamped": (255, 165, 0)
}

# âœ… ë°°ê²½ ì œê±° í´ë˜ìŠ¤
class ImageProcessor:
    @staticmethod
    def preprocess_image(image):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬: RGB ë³€í™˜ ë° í¬ê¸° ì¡°ì •"""
        if image.mode in ["RGBA", "P", "L"]:
            image = image.convert("RGB")
        image = image.resize((500, 500))  # âœ… ëª¨ë¸ì— ë§ê²Œ í¬ê¸° ì¡°ì •
        return image

# âœ… ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ í´ë˜ìŠ¤
class DefectDetector:
    @st.cache_resource
    def load_model(model_path):
        model = models.detection.maskrcnn_resnet50_fpn(pretrained=False)
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 5)
        state_dict = torch.load(model_path, map_location=torch.device("cpu"))
        model.load_state_dict(state_dict, strict=False)
        model.eval()
        return model

    @staticmethod
    def predict(image, model):
        try:
            # âœ… ì´ë¯¸ì§€ íƒ€ì… ë° ì •ë³´ ì¶œë ¥
            st.write(f"ğŸ“Œ **ì´ë¯¸ì§€ íƒ€ì…:** {type(image)}")
            st.write(f"ğŸ“Œ **PIL ëª¨ë“œ:** {image.mode}")

            # âœ… numpy ë³€í™˜ í™•ì¸
            image_np = np.array(image)
            st.write(f"ğŸ“Œ **numpy ë³€í™˜ ì™„ë£Œ:** {image_np.shape}, dtype={image_np.dtype}")

            # âœ… Tensor ë³€í™˜ ì‹œë„ (ì˜¤ë¥˜ ë°œìƒ ì—¬ë¶€ í™•ì¸)
            try:
                image_tensor = F.to_tensor(image).unsqueeze(0)
                st.write("âœ… `to_tensor()` ë³€í™˜ ì„±ê³µ!")
            except Exception as e:
                st.error(f"âŒ `to_tensor()` ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return None, 0, [], []

            # âœ… ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
            with torch.no_grad():
                outputs = model(image_tensor)

            scores = outputs[0]['scores'].detach().numpy()
            boxes = outputs[0]['boxes'].detach().numpy()
            labels = outputs[0]['labels'].detach().numpy()
            masks = outputs[0]['masks'].detach().squeeze().numpy()

            # âœ… ì˜ˆì¸¡ ê²°ê³¼ í•„í„°ë§
            threshold = 0.5
            selected = scores >= threshold

            if not np.any(selected) or len(boxes) == 0:
                return image, 0, [], []

            return boxes[selected], labels[selected], masks[selected]

        except Exception as e:
            st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, 0, [], []

# âœ… ì‹œê°í™” í´ë˜ìŠ¤
class Visualizer:
    @staticmethod
    def visualize(image, boxes, labels, masks, mask_display, mask_alpha, line_thickness):
        image_np = np.array(image)

        if mask_display == "ë§ˆìŠ¤í‚¹ ì˜ì—­ í‘œì‹œ":
            mask = np.zeros_like(image_np, dtype=np.uint8)
            for i, m in enumerate(masks):
                m = (m > 0.5).astype(np.uint8) * 255
                color = LABEL_COLORS.get(int(labels[i]), (255, 255, 255))
                mask[m > 0] = color
            output = cv2.addWeighted(image_np, 1 - mask_alpha, mask, mask_alpha, 0)
        else:
            output = draw_bounding_boxes(
                torch.tensor(image_np).permute(2, 0, 1),
                torch.tensor(boxes),
                labels=[CLASS_NAMES.get(int(l), "unknown") for l in labels],
                colors=[LABEL_COLORS.get(int(l), (255, 255, 255)) for l in labels],
                width=line_thickness,
            ).permute(1, 2, 0).numpy()

        return Image.fromarray(output)

# âœ… Streamlit UI
st.title("O-Ring Defect Detection")
st.sidebar.header("ì„¤ì •")

mask_display = st.sidebar.radio("ë§ˆìŠ¤í‚¹ í‘œì‹œ ì˜µì…˜", ["ë§ˆìŠ¤í‚¹ ì˜ì—­ í‘œì‹œ", "ê²½ê³„ì„ ë§Œ í‘œì‹œ"])
mask_alpha = st.sidebar.slider("ë§ˆìŠ¤í‚¹ íˆ¬ëª…ë„", 0.1, 1.0, 0.5) if mask_display == "ë§ˆìŠ¤í‚¹ ì˜ì—­ í‘œì‹œ" else 0.5
line_thickness = st.sidebar.slider("ê²½ê³„ì„  ë‘ê»˜", 1, 5, 2) if mask_display == "ê²½ê³„ì„ ë§Œ í‘œì‹œ" else 2

model_option = st.sidebar.selectbox("ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ", list(MODEL_PATHS.keys()))
model = DefectDetector.load_model(MODEL_PATHS[model_option])

uploaded_files = st.sidebar.file_uploader("O-Ring ì´ë¯¸ì§€ ì—…ë¡œë“œ (ë‹¤ì¤‘ ê°€ëŠ¥)", accept_multiple_files=True, type=["png", "jpg", "jpeg"])

if uploaded_files:
    batch_processing = st.sidebar.checkbox("ì „ì²´ ë¶„ì„ ì‹¤í–‰")

    file_dict = {file.name: file for file in uploaded_files}

    for file_name, file in file_dict.items() if batch_processing else [list(file_dict.items())[0]]:
        image = Image.open(file).convert("RGB")
        processed_image = ImageProcessor.preprocess_image(image)

        boxes, labels, masks = DefectDetector.predict(processed_image, model)
        result_image = Visualizer.visualize(processed_image, boxes, labels, masks, mask_display, mask_alpha, line_thickness)
        st.image(result_image, caption=f"ê²°ê³¼: {file_name}", use_container_width=True)
