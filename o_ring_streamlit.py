import streamlit as st
import torch
import numpy as np
import cv2
import torchvision.transforms.functional as F
from torchvision.utils import draw_bounding_boxes
from PIL import Image
import torchvision.models as models
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import json
import io

# âœ… ëª¨ë¸ ê²½ë¡œ ì„¤ì •
MODEL_PATHS = {
    "Baseline Model": "train_test_100.pth",
    "K-Fold Model": "k_fold_35_epoch_2.pth",
    "Ensemble Model": "ensemble_model_35_epoch.pth"
}

# âœ… ëª¨ë¸ ì„¤ëª… ê°€ì´ë“œ
MODEL_DESCRIPTIONS = {
    "Baseline Model": "ë¹ ë¥¸ ê²°ê³¼ê°€ í•„ìš”í•˜ê±°ë‚˜ ê¸°ë³¸ì ì¸ ê²€ì‚¬ë¥¼ ì›í•  ë•Œ ì¶”ì²œí•©ë‹ˆë‹¤.",
    "K-Fold Model": "ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œë„ ì•ˆì •ì ì¸ ê²€ì‚¬ê°€ í•„ìš”í•  ë•Œ ì„ íƒí•˜ì„¸ìš”.",
    "Ensemble Model": "ê°€ì¥ ì •í™•í•œ ê²€ì‚¬ê°€ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•˜ì„¸ìš”."
}

# âœ… í´ë˜ìŠ¤ ë§¤í•‘
CLASS_NAMES = {1: "extruded", 2: "crack", 3: "cutting", 4: "side_stamped"}

# âœ… ë¼ë²¨ë³„ ìƒ‰ìƒ ì§€ì •
LABEL_COLORS = {
    "extruded": (255, 0, 0),    
    "crack": (0, 0, 255),        
    "cutting": (0, 255, 0),      
    "side_stamped": (255, 165, 0)  
}

# âœ… ì•„ì´ì½˜ ë§¤í•‘
ICON_MAPPING = {
    "extruded": "ğŸ”´",
    "crack": "ğŸ”µ",
    "cutting": "ğŸŸ¢",
    "side_stamped": "ğŸŸ "
}

# âœ… ë°°ê²½ ì œê±° í•¨ìˆ˜
def remove_background(image_np):
    """ë¶ˆí•„ìš”í•œ ë°°ê²½ ì œê±° (ì´ì§„í™” + ì»¨íˆ¬ì–´ ê²€ì¶œ í™œìš©)"""
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

    # âœ… ê°€ì¥ í° ì»¨íˆ¬ì–´ë¥¼ ì°¾ì•„ì„œ í•´ë‹¹ ì˜ì—­ë§Œ ë‚¨ê¹€
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        x, y, w, h = cv2.boundingRect(np.concatenate(contours))
        image_np = image_np[y:y+h, x:x+w]  # ë°°ê²½ì„ ì œê±°í•œ ê´€ì‹¬ ì˜ì—­
    return image_np

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ (ë°°ê²½ ì œê±° í¬í•¨)
class ImageProcessor:
    @staticmethod
    def preprocess_image(image):
        """RGB ë³€í™˜ + ë°°ê²½ ì œê±° + í¬ê¸° ì¡°ì •"""
        if image.mode in ["RGBA", "P", "L"]:
            image = image.convert("RGB")
        image_np = np.array(image)
        image_np = remove_background(image_np)  # âœ… ë°°ê²½ ì œê±° ìˆ˜í–‰
        image = Image.fromarray(image_np).resize((500, 500))  # âœ… ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ì¡°ì •
        return image

# âœ… ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ í´ë˜ìŠ¤
class DefectDetector:
    @st.cache_resource
    def load_model(model_path):
        model = models.detection.maskrcnn_resnet50_fpn(pretrained=False)
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 5)
        state_dict = torch.load(model_path, map_location=torch.device("cpu"))
        model.load_state_dict(state_dict, strict=False)
        model.eval()
        return model

    @staticmethod
    def predict(image, model):
        try:
            # âœ… ì´ë¯¸ì§€ ë³€í™˜ (PIL â†’ Tensor)
            image_tensor = F.to_tensor(image).unsqueeze(0)
            
            # ì‹ ë¢°ë„ ì„ê³„ê°’ (Threshold) ì„¤ì •
            confidence_threshold = 0.5

            # âœ… ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
            with torch.no_grad():
                outputs = model(image_tensor)

            scores = outputs[0]['scores'].detach().numpy() if 'scores' in outputs[0] else []
            filtered_scores = [s for s in scores if s >= confidence_threshold]
            boxes = outputs[0]['boxes'].detach().numpy()
            labels = outputs[0]['labels'].detach().numpy()
            masks = outputs[0]['masks'].detach().squeeze().numpy()

            # âœ… ì˜ˆì¸¡ ê²°ê³¼ í•„í„°ë§ (ì‹ ë¢°ë„ 0.5 ì´ìƒë§Œ)
            threshold = 0.5
            selected = np.where(scores >= threshold)[0]

            # âœ… ê²°í•¨ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì˜¤ë¥˜ ë°©ì§€)
            if len(selected) == 0:
                return [], [], []

            return boxes[selected], labels[selected], masks[selected]

        except Exception as e:
            st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return [], [], []  # âœ… ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

# âœ… ì‹œê°í™” í´ë˜ìŠ¤ ì¶”ê°€
class Visualizer:
    @staticmethod
    def visualize(image, boxes, labels, masks, mask_display, mask_alpha, line_thickness, contour_thickness):
        image_np = np.array(image)

        if mask_display == "ë§ˆìŠ¤í‚¹ ì˜ì—­ í‘œì‹œ":
            mask = np.zeros_like(image_np, dtype=np.uint8)
            for i, m in enumerate(masks):
                m = (m > 0.5).astype(np.uint8) * 255
                color = LABEL_COLORS.get(CLASS_NAMES[int(labels[i])], (255, 255, 255))
                mask[m > 0] = color

            if len(mask.shape) == 2 or mask.shape[-1] == 1:
                mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)

            output = cv2.addWeighted(image_np, 1 - mask_alpha, mask, mask_alpha, 0)

        else:
            output = image_np.copy()
            for i, m in enumerate(masks):
                m = (m > 0.5).astype(np.uint8)
                contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                color = LABEL_COLORS.get(CLASS_NAMES[int(labels[i])], (255, 255, 255))
                cv2.drawContours(output, contours, -1, color, contour_thickness)

        # âœ… ë°”ìš´ë”© ë°•ìŠ¤ & ê²°í•¨ ì¢…ë¥˜ ì¶”ê°€ (ë§ˆìŠ¤í‚¹ & ê²½ê³„ì„  ì˜µì…˜ ëª¨ë‘ í¬í•¨)
        if len(boxes) > 0:
            boxes_tensor = torch.tensor(boxes, dtype=torch.float)
            labels_list = [CLASS_NAMES.get(int(l), "unknown") for l in labels]
            colors_list = [LABEL_COLORS.get(CLASS_NAMES[int(l)], (255, 255, 255)) for l in labels]

            output = draw_bounding_boxes(
                torch.tensor(output).permute(2, 0, 1),
                boxes_tensor,
                colors=colors_list,
                width=line_thickness,
            ).permute(1, 2, 0).numpy()

            # âœ… ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì— ê¸€ì ë°°ê²½ ì¶”ê°€
            for i, (box, label) in enumerate(zip(boxes, labels_list)):
                x1, y1 = int(box[0]), int(box[1])  # ì™¼ìª½ ìƒë‹¨ ì¢Œí‘œ

                # âœ… ë°°ê²½ ì‚¬ê°í˜• (ê¸€ì í¬ê¸° ë§ì¶”ê¸° ìœ„í•´ ì¡°ì •)
                text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
                text_w, text_h = text_size
                cv2.rectangle(output, (x1, y1 - text_h - 4), (x1 + text_w + 4, y1), (50, 50, 50), -1)  # âœ… ë°°ê²½ ë°•ìŠ¤ ì¶”ê°€

                # âœ… ê¸€ì ì¶”ê°€
                cv2.putText(output, label, (x1 + 2, y1 - 2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        return Image.fromarray(output)

# âœ… JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„± (ê²°ê³¼ë¥¼ í™•ì¸í•œ ì´ë¯¸ì§€ë§Œ ì €ì¥)
json_results = []

# âœ… JSON ë°ì´í„° ë³€í™˜ í•¨ìˆ˜ (ì •ìƒ ì´ë¯¸ì§€ë„ í¬í•¨)
def add_to_json_results(file_name, boxes, labels):
    """ê²°ê³¼ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ í›„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"""
    results = []
    for i in range(len(labels)):
        result = {
            "class": CLASS_NAMES.get(int(labels[i]), "unknown"),
            "bounding_box": [float(coord) for coord in boxes[i]]
        }
        results.append(result)

    json_data = {
        "file_name": file_name,
        "detections": results  # ê²°í•¨ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ []
    }

    # âœ… JSON ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
    json_results.append(json_data)
        
# âœ… UI êµ¬ì„±
st.title("O-Ring Defect Detection")
model_option = st.selectbox("ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ", list(MODEL_PATHS.keys()))

# âœ… ì„ íƒëœ ëª¨ë¸ ì„¤ëª… í‘œì‹œ
st.write(f"ğŸ“Œ **ì„ íƒí•œ ëª¨ë¸:** {model_option}")  
st.info(MODEL_DESCRIPTIONS[model_option])  # ëª¨ë¸ ì„¤ëª… í‘œì‹œ

mask_display = st.radio("ë§ˆìŠ¤í‚¹ í‘œì‹œ ì˜µì…˜", ["ë§ˆìŠ¤í‚¹ ì˜ì—­ í‘œì‹œ", "ê²½ê³„ì„ ë§Œ í‘œì‹œ"])
mask_alpha = st.slider("ë§ˆìŠ¤í‚¹ íˆ¬ëª…ë„", 0.1, 0.7, 0.3, step=0.1) if mask_display == "ë§ˆìŠ¤í‚¹ ì˜ì—­ í‘œì‹œ" else 0.5
line_thickness = int(st.slider("ë°”ìš´ë”© ë°•ìŠ¤ ë‘ê»˜", 1.0, 3.0, 1.5, step=0.5))
contour_thickness = int(st.slider("ê²½ê³„ì„  ë‘ê»˜", 1.0, 3.0, 1.5, step=0.5)) if mask_display == "ê²½ê³„ì„ ë§Œ í‘œì‹œ" else 2

uploaded_files = st.file_uploader("O-Ring ì´ë¯¸ì§€ ì—…ë¡œë“œ (ë‹¤ì¤‘ ê°€ëŠ¥)", accept_multiple_files=True, type=["png", "jpg", "jpeg"])

if uploaded_files:
    selected_file = st.sidebar.selectbox("ê²°ê³¼ë¥¼ í™•ì¸í•  ì´ë¯¸ì§€ ì„ íƒ", [file.name for file in uploaded_files])
    file_dict = {file.name: file for file in uploaded_files}
    image = Image.open(file_dict[selected_file]).convert("RGB")
    processed_image = ImageProcessor.preprocess_image(image)  
    model = DefectDetector.load_model(MODEL_PATHS[model_option])
    boxes, labels, masks = DefectDetector.predict(processed_image, model)

    # âœ… JSON ë°ì´í„° ì €ì¥ (ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°ë„ í¬í•¨)
    add_to_json_results(selected_file, boxes, labels)

    # âœ… ê²°ê³¼ê°€ ìˆì„ ê²½ìš° ì‹œê°í™”
    if len(boxes) > 0:
        result_image = Visualizer.visualize(processed_image, boxes, labels, masks, mask_display, mask_alpha, line_thickness, contour_thickness)
        st.image(result_image, caption=f"ê²°ê³¼: {selected_file}", use_container_width=True)
        
        # âœ… íƒì§€ëœ ê²°í•¨ ì •ë³´ ìš”ì•½
        defect_counts = {}
        for label in labels:
            class_name = CLASS_NAMES.get(int(label), "unknown")
            defect_counts[class_name] = defect_counts.get(class_name, 0) + 1

        # âœ… ì‹ ë¢°ë„(Confidence) í‰ê· ê°’ ê³„ì‚°
        scores = model(F.to_tensor(processed_image).unsqueeze(0))[0]['scores'].detach().numpy()
        avg_confidence = np.mean(filtered_scores) if len(scores) > 0 else 0
                        
        # âœ… íƒì§€ëœ ê²°í•¨ ì •ë³´ í‘œì‹œ
        st.write(f"ğŸ“Š **íƒì§€ëœ ê²°í•¨ ìš”ì•½ ({selected_file})**")
        for defect, count in defect_counts.items():
            st.write(f"- {ICON_MAPPING.get(defect, '')} **{defect}**: {count}ê°œ")
        st.write(f"ğŸ” **í‰ê·  ì‹ ë¢°ë„:** {avg_confidence:.2f}")   
             
        # âœ… ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Bytesë¡œ ë³€í™˜
        img_byte_arr = io.BytesIO()
        result_image.save(img_byte_arr, format="PNG")
        img_byte_arr = img_byte_arr.getvalue()

        # âœ… Streamlit ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
        st.download_button(
            label="ğŸ“· ì‹œê°í™”ëœ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
            data=img_byte_arr,
            file_name=f"{selected_file}_result.png",
            mime="image/png"
        )
        
    else:
        st.image(processed_image, caption=f"âœ… ì •ìƒ ì´ë¯¸ì§€: {selected_file}", use_container_width=True)
        st.write("âœ… **ì •ìƒì…ë‹ˆë‹¤! ê²°í•¨ì´ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")

# âœ… JSON ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€ (JSON ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ)
if json_results:
    st.write("ğŸ“¥ **ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë“¤ì˜ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**")
    
    if st.button("ğŸ“¥ JSON ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ"):
        json_path = "results.json"
        with open(json_path, "w") as json_file:
            json.dump(json_results, json_file, indent=4)

        # âœ… JSON ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
        with open(json_path, "rb") as file:
            st.download_button(
                label="ğŸ“¥ JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=file,
                file_name="results.json",
                mime="application/json"
            )

        st.success("ğŸ“ JSON íŒŒì¼ì´ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì™„ë²½í•œ ëª¨ë¸